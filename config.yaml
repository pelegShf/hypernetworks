train:
  lr: 1.0
  batch_size: 64
  epochs: 20
  gamma: 0.7
  n_classes: 10
  seed: 42
  normalize: 1

model:
  layer_dims: [784, 64, 10]
  emb_dim: 5
  cnn_cond: true
  clip_grad: 0.7
  data_dir: "./Data/mnist"

log:
  interval: 100
  run_dir: runs/mnist_hypernet
  verbose: false


testing:
  batch_size: 10

misc:
  workers: 8